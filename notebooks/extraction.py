# -*- coding: utf-8 -*-
"""Heart_Disease_ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YauFhxMtgWop1eZ8DgH0Y13fSmbmDtY0
"""

# Install opensmile and other necessary libraries
# !pip install librosa soundfile pandas numpy scikit-learn tensorflow matplotlib seaborn scipy PyWavelets opensmile

# from google.colab import drive
# drive.mount('/content/drive')

# zip_file_path = "/content/drive/My Drive/Heart Sounds/BMD-HS-Dataset-main.zip"
# destination_path = "/content/drive/My Drive/Heart Sounds/BMD-HS-Dataset-unzipped"
# config_path = "/content/opensmile/config/gemaps/eGeMAPSv01a.conf"

# !unzip -q "$zip_file_path" -d "$destination_path"

#import opensmile as open
import librosa as lib
import soundfile as sf
import pandas as pd
import numpy as np
import sklearn
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
import os
import scipy as scipy
import multiprocessing
import pywt

import opensmile

smile = opensmile.Smile(
    feature_set=opensmile.FeatureSet.eGeMAPSv01a,  # or FeatureSet.ComParE_2016
    feature_level=opensmile.FeatureLevel.Functionals,
)

# dataset_root_dir = os.path.join(destination_path, 'BMD-HS-Dataset-main')

# #Reading in our data
# train_csv_path = os.path.join(dataset_root_dir, 'train.csv')
# train_csv = pd.read_csv(train_csv_path)

# metadata_path = os.path.join(dataset_root_dir, 'additional_metadata.csv')
# metadata = pd.read_csv(metadata_path)

# eco_path = os.path.join(dataset_root_dir, 'eco.xlsx')
# eco_data = pd.read_excel(eco_path)

# #inspecting my data
# train_csv.head()
# # metadata.head()
# eco_data.head()

#Merging our metadata with our training dataset


df = pd.merge(train_csv,metadata,how = "left",on ="patient_id")
df

# This is the base directory containing all audio subfolders
BASE_AUDIO_DIR = os.path.join(dataset_root_dir, 'train')

print(BASE_AUDIO_DIR)
print("Exists:", os.path.exists(BASE_AUDIO_DIR))
print("Contents:", os.listdir(BASE_AUDIO_DIR))

import glob

# Base audio directory
BASE_AUDIO_DIR = "/content/drive/My Drive/Heart Sounds/BMD-HS-Dataset-unzipped/BMD-HS-Dataset-main/train"

# All .wav files directly inside the train/ folder
all_audio_files = glob.glob(os.path.join(BASE_AUDIO_DIR, "*.wav"))

print(f"Found {len(all_audio_files)} .wav files")
print("Examples:")
for path in all_audio_files[:5]:
    print(path)

audio_lookup = {
    os.path.splitext(os.path.basename(path))[0]: path
    for path in all_audio_files
}
print(f"Found {len(all_audio_files)} .wav files. Example key in lookup: {list(audio_lookup.keys())[0] if audio_lookup else 'N/A'}")

# print(train_csv.columns)
# print(train_csv.head())
# train_csv['patient_id'] = train_csv['patient_id'].str.replace('patient_', 'AR_')

# First, melt the DataFrame so each row is one recording
# Melt the recordings into long format
melted_df = df.melt( # Use df_merged now that patient metadata is included
    id_vars=['patient_id', 'AS', 'AR', 'MR', 'MS', 'N'] + [col for col in df.columns if col not in [f"recording_{i}" for i in range(1, 9)] and col not in ['patient_id', 'AS', 'AR', 'MR', 'MS', 'N']],
    value_vars=[f"recording_{i}" for i in range(1, 9)],
    var_name="recording_slot",
    value_name="audio_filename_base" # Renamed for clarity: this is the filename part
)


melted_df

melted_clean = melted_df.drop('recording_slot', axis = 'columns')
melted_clean

# Combine patient_id and position_info to match filename format
# Ex: 'AR_016' + '_' + 'sit_Aor' --> 'AR_016_sit_Aor'
melted_df['file_key'] = melted_df['audio_filename_base']
melted_df["file_key"]

melted_df['audio_path'] = melted_df['file_key'].map(audio_lookup)



# Check results
# print(melted_df[['file_key', 'audio_path']].dropna().head())


# Drop rows with no match (missing audio files)
melted_df = melted_df.dropna(subset=["audio_path"])
melted_df

for index, row in melted_df.iterrows():
  current_audio_file_path = row['audio_path']
  if pd.isna(current_audio_file_path): # Checks for NaN values
    print(f"Skipping row {index}: Audio path is missing.")
    continue # Skip to the next iteration

  if not os.path.exists(current_audio_file_path):
      print(f"Skipping row {index}: File not found at {current_audio_file_path}")
      continue # Skip to the next iteration
  y, sr = lib.load(current_audio_file_path, sr=4000)

"""Right now for the feature extraction, I'm just iterating through my elongated through each of the recordings and then extracting features.

*   the rms energy is just how loud each audio signal is across different frames and that's why i used frame length - to split the audio into different segments, murmurs and clicks can increase the RMS ,the variation and skew causes unpredictable energy patterns which are indicative of an unhealthy heart.
*  spectral centroid is the central of mass of an audio. a shift  in this could mean change in blood flow dynamics due to stenosis or regurgitation
*   bandrwidth just measures the spread of frequencies
*   contrast just tells us how distinct prominent components are from surrounding quieter frequencies











"""

#function for feature engineering to get RMS Energy and the stats from that energy
def extract_features_singular(row_data):
  current_audio_file_path = row_data['audio_path']
  patient_id = row_data['patient_id']
  file_key = row_data['file_key']

  # smile = opensmile.Smile(
  #     feature_set = opensmile.FeatureSet.eGeMAPSv01a.conf,
  # )

  if pd.isna(current_audio_file_path): # Checks for NaN values
      print(f"Skipping row {index}: Audio path is missing.")
      return None

  if not os.path.exists(current_audio_file_path):
      print(f"Skipping row {index}: File not found at {current_audio_file_path}")
      return None
  try:
    y, sr = lib.load(current_audio_file_path, sr=4000)
    # Feature Extraction
    zero_crossings = lib.feature.zero_crossing_rate(y)
    rms_energy = lib.feature.rms(y=y,frame_length = 2048, hop_length=512).flatten()
    spectral_centroid = lib.feature.spectral_centroid(y=y, sr=4000)
    spectral_bandwidth = lib.feature.spectral_bandwidth(y=y, sr=4000)
    spectral_contrast = lib.feature.spectral_contrast(y=y, sr=4000,n_bands = 4)
    mfccs = lib.feature.mfcc(y = y,sr = 4000, n_fft=8192, hop_length = 10)
  #  chroma_cqt = lib.feature.chroma_stft(y=y, sr=4000)
    log_mel_spect = lib.feature.melspectrogram(y = y, sr=sr)
    cqt = lib.cqt(y, sr=sr, hop_length=512, n_bins=10, bins_per_octave=12)
    cqt_db = lib.amplitude_to_db(np.abs(cqt))


    #collecting stats from features
    mean_zero_crossings = np.mean(zero_crossings)
    mean_rms = np.mean(rms_energy)
    sd_rms = np.std(rms_energy)
    skewness_rms = scipy.stats.skew(rms_energy)
    mean_spectral_centroid = np.mean(spectral_centroid)
    mean_spectral_bandwidth = np.mean(spectral_bandwidth)
    mean_spectral_contrast = np.mean(spectral_contrast)
    mean_mfccs = np.mean(mfccs)
    sd_mfccs = np.std(mfccs, axis=1)
    #mean_chroma = np.mean(chroma_cqt)
    mean_mel_spect = np.mean(log_mel_spect)
    sd_mel_spect = np.std(log_mel_spect)
    mean_cqt = np.mean(cqt_db)
    std_cqt = np.std(cqt_db)
    skew_cqt = scipy.stats.skew(cqt_db.flatten())



    #preparing into dictionary
    features = {
    "patient_id": patient_id,
    "filekey": file_key,
    "Mean Zero Crossing Rate": mean_zero_crossings,
    'Mean RMS': mean_rms,
    "Standard Dev. RMS" : sd_rms,
    'Skewness RMS': skewness_rms,
    'Mean Spectral Centroid': mean_spectral_centroid,
    'Mean Spectral Bandwidth': mean_spectral_bandwidth,
    'Mean Spectral Contrast': mean_spectral_contrast,
    'mfcc length' : mean_mfccs,
    'mfcc devation' : sd_mfccs,
    'mean mel spectogram' : mean_mel_spect,
    'mel spectrogram deviation' : sd_mel_spect,
    "CQT Mean": mean_cqt,
    "CQT Std": std_cqt,
    "CQT Skew": skew_cqt,

    #mean chroma': mean_chroma
    }

    return features

  except Exception as e:
   print(f"Error processing {current_audio_file_path}: {e}")
   return None



#I'm using multiprocessing pool to extract the features in parallel/simultaneously to speed this up
def extract_features_parallelized(df,num_processes = None):
  if num_processes is None:
    num_processes = os.cpu_count()

  rows_to_process  = df[['audio_path', 'patient_id', 'file_key']].to_dict(orient='records')
  with multiprocessing.Pool(processes=num_processes)as pool:
    results = pool.map(extract_features_singular,rows_to_process)
  features_list = []
  for result in results :
    if result is not None:
      features_list.append(result)
  features_df = pd.DataFrame(features_list)
  return features_df



final_features_dataframe = extract_features_parallelized(melted_df)
final_features_dataframe

opensmile_feature_list = []
for index, row in melted_df.iterrows():
  current_audio_file_path = row['audio_path']
  patient_id = row['patient_id']
  file_key = row['file_key']

  smile_df = smile.process_file(current_audio_file_path)
  smile_df.to_csv("opensmile_features.csv")
  smile_df['patient_id'] = patient_id
  smile_df['file_key'] = file_key

  opensmile_feature_list.append(smile_df.iloc[0].to_dict())


opensmile_features_df = pd.DataFrame(opensmile_feature_list)

# Save once to CSV
# opensmile_features_df.to_csv("opensmile_features_full.csv", index=False)

#might just drop these
opensmile_modified = opensmile_features_df.drop(columns=['F0semitoneFrom27.5Hz_sma3nz_amean', 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm','F0semitoneFrom27.5Hz_sma3nz_percentile20.0',
       'F0semitoneFrom27.5Hz_sma3nz_percentile50.0',
       'F0semitoneFrom27.5Hz_sma3nz_percentile80.0',
       'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',
       'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',
       'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',
       'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope',
       'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',
                               "VoicedSegmentsPerSec", 'MeanVoicedSegmentLengthSec', 'StddevVoicedSegmentLengthSec','StddevUnvoicedSegmentLength'])
opensmile_modified

def extract_hnr_single(row):
    audio_path = row["audio_path"]
    file_key = row["file_key"]

    try:
        if not os.path.exists(audio_path):
            return {"file_key": file_key, "HNR": None}

        features = smile.process_file(audio_path)

        # Search for HNR-related columns
        hnr_columns = [col for col in features.columns if 'HNR' in col]

        if not hnr_columns:
            return {"file_key": file_key, "HNR": None}

        hnr_value = features[hnr_columns[0]].values[0]  # take the first HNR feature
        return {"file_key": file_key, "HNR": hnr_value}

    except Exception as e:
        print(f"Error on {file_key}: {e}")
        return {"file_key": file_key, "HNR": None}

from tqdm import tqdm

hnr_results = [extract_hnr_single(row) for _, row in tqdm(melted_df.iterrows(), total=len(melted_df))]
hnr_df = pd.DataFrame(hnr_results)

# from tqdm import tqdm

# hnr_results = [extract_hnr_single(row) for _, row in tqdm(melted_df.iterrows(), total=len(melted_df))]
# hnr_df.to_csv('hnr_df.csv')
hnr_df

for _, row in melted_df.head(5).iterrows():
    print(extract_hnr_single(row))

print(final_features_df.columns)
print(final_features_dataframe.columns)

hnr_df.rename(columns={' 1 ': 'file_key'}, inplace=True)

hnr_df

test_path = melted_df["audio_path"].iloc[0]  # Use any valid path
features = smile.process_file(test_path)
print(features.columns)

final_features_dataframe.rename(columns={'filekey': 'file_key'}, inplace=True)
final_features_dataframe

# final_features_df = pd.merge(final_features_dataframe, melted_clean, on="filekey", how="left")
# melted_clean
final_features_dataframe = pd.merge(final_features_dataframe, opensmile_modified, on="file_key", how="left") #this is the one with the opensmle
final_features_dataframe = pd.merge(final_features_dataframe, melted_clean, on="file_key", how="left") #this is the mixing with the metadata

# final_features_dataframe.drop('patient_id_x',axis = 'columns')
# opensmile_modified.drop('patient_id_x',axis = 'columns')
# melted_clean.drop('patient_id_x',axis = 'columns')
final_features_dataframe.columns

from google.colab import files

final_features_dataframe.to_csv('final_dataframe.csv')
files.download('final_dataframe.csv')

opensmile_modified.to_csv('open_Smle_df.csv')
files.download('open_Smle_df.csv')

melted_clean.to_csv('melted_clean.csv')
files.download('melted_clean.csv')

def make_scalogram_single(row_data):
  current_audio_file_path = row_data['audio_path']
  patient_id = row_data['patient_id']
  file_key = row_data['file_key']

  # smile = opensmile.Smile(
  #     feature_set = opensmile.FeatureSet.eGeMAPSv01a.conf,
  # )

  if pd.isna(current_audio_file_path): # Checks for NaN values
      print(f"Skipping row {index}: Audio path is missing.")
      return None

  if not os.path.exists(current_audio_file_path):
      print(f"Skipping row {index}: File not found at {current_audio_file_path}")
      return None
  try:
    y, sr = lib.load(current_audio_file_path, sr=4000)
    wavelet = 'morl'
    min_scale = 1
    max_scale = 512
    num_scales = 128
    scales = np.power(2, np.linspace(np.log2(min_scale),np.log2(max_scale),num_scales))
    sampling_period = 1/ sr
    coefficients,frequencies = pywt.cwt(y,scales, wavelet=wavelet,sampling_period = sampling_period)
    sns.heatmap(np.abs(coefficients),
            cmap='viridis',
            cbar_kws={'label': 'Magnitude'}
           )
 #storing the scalograms
    output_dir = 'scalogram_images'
    os.makedirs(output_dir, exist_ok=True)
    image_filename = os.path.join(output_dir, f'scalogram_{file_key}.png')
    np.save(os.path.join(output_dir, f'scalogram_{file_key}.npy'), coefficients)
    plt.savefig(image_filename)
    plt.close()
    return {'patient_id': patient_id, 'file_key': file_key, 'image_path': image_filename}

  except Exception as e:
    print(f"Error processing {current_audio_file_path}: {e}")
    return None

def make_scalograms_parallelized(df,num_processes = None):
  rows_to_process  = df[['audio_path', 'patient_id', 'file_key']].to_dict(orient='records')
  if num_processes is None:
    num_processes = os.cpu_count()
  with multiprocessing.Pool(processes=num_processes)as pool:
     new_results = pool.map(make_scalogram_single,rows_to_process)
     valid_results = []
     for result in new_results:
      if result is not None:
        valid_results.append(result)
  return pd.DataFrame(valid_results)
